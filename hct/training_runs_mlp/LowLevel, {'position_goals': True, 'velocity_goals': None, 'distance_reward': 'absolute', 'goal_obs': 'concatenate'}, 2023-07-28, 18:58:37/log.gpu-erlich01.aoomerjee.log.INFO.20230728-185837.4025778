I0728 18:58:37.898223 139857045534528 low_level_env.py:190] Initialising environment...
I0728 18:58:38.226968 139857045534528 low_level_env.py:298] Environment initialised.
I0728 18:58:38.231222 139857045534528 train.py:118] JAX is running on GPU.
I0728 18:58:38.231270 139857045534528 train.py:121] Device count: 2, process count: 1 (id 0), local device count: 2, devices to be used count: 2
I0728 18:58:44.514655 139857045534528 train.py:367] Running initial eval
I0728 18:58:59.940919 139857045534528 train.py:373] {'eval/walltime': 15.286954641342163, 'eval/episode_goal_distance_relative_frame_normalised': Array([0.32026422, 0.12827416], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([27.080727, 11.030229], dtype=float32), 'eval/episode_reward': Array([-25644.531,   9753.119], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.31613636, 0.13073914], dtype=float32), 'eval/avg_episode_length': Array([1000.,    0.], dtype=float32), 'eval/epoch_eval_time': 15.286954641342163, 'eval/sps': 8373.152338258124}
I0728 18:58:59.942323 139857045534528 train.py:379] starting iteration 0, 0 steps, 21.711127281188965
I0728 18:59:50.863616 139857045534528 train.py:394] {'eval/walltime': 18.890188932418823, 'training/sps': 235472.50681227236, 'training/walltime': 47.31388878822327, 'training/entropy_loss': Array(-0.03491348, dtype=float32), 'training/policy_loss': Array(-0.00466003, dtype=float32), 'training/total_loss': Array(20422.328, dtype=float32), 'training/v_loss': Array(20422.37, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.11744697, 0.09860151], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([9.578506, 8.431831], dtype=float32), 'eval/episode_reward': Array([-12660.362 ,   7320.8853], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.10235259, 0.10468089], dtype=float32), 'eval/avg_episode_length': Array([1000.,    0.], dtype=float32), 'eval/epoch_eval_time': 3.60323429107666, 'eval/sps': 35523.640612820964}
I0728 18:59:50.880488 139857045534528 train.py:379] starting iteration 1, 11141120 steps, 72.64929723739624
I0728 19:00:29.878413 139857045534528 train.py:394] {'eval/walltime': 22.522987127304077, 'training/sps': 315064.42430356337, 'training/walltime': 82.67529153823853, 'training/entropy_loss': Array(-0.01584023, dtype=float32), 'training/policy_loss': Array(-0.00326933, dtype=float32), 'training/total_loss': Array(1514.1658, dtype=float32), 'training/v_loss': Array(1514.1849, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.10787936, 0.11287727], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([8.550064, 9.707021], dtype=float32), 'eval/episode_reward': Array([-10326.154,   8989.835], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.09177769, 0.11956235], dtype=float32), 'eval/avg_episode_length': Array([1000.,    0.], dtype=float32), 'eval/epoch_eval_time': 3.632798194885254, 'eval/sps': 35234.54734706039}
I0728 19:00:29.880357 139857045534528 train.py:379] starting iteration 2, 22282240 steps, 111.64916753768921
I0728 19:01:08.897409 139857045534528 train.py:394] {'eval/walltime': 26.166115283966064, 'training/sps': 314984.94775277085, 'training/walltime': 118.0456166267395, 'training/entropy_loss': Array(-0.00694754, dtype=float32), 'training/policy_loss': Array(-0.00419152, dtype=float32), 'training/total_loss': Array(1645.9158, dtype=float32), 'training/v_loss': Array(1645.927, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.10886449, 0.12717474], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 8.227379, 11.043887], dtype=float32), 'eval/episode_reward': Array([-9920.723, 10355.402], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.09661981, 0.1313686 ], dtype=float32), 'eval/avg_episode_length': Array([1000.,    0.], dtype=float32), 'eval/epoch_eval_time': 3.6431281566619873, 'eval/sps': 35134.64102708917}
I0728 19:01:08.898975 139857045534528 train.py:379] starting iteration 3, 33423360 steps, 150.6677851676941
I0728 19:01:47.988100 139857045534528 train.py:394] {'eval/walltime': 29.817513465881348, 'training/sps': 314420.2100527843, 'training/walltime': 153.47947120666504, 'training/entropy_loss': Array(-0.00012802, dtype=float32), 'training/policy_loss': Array(-0.00328731, dtype=float32), 'training/total_loss': Array(1557.6567, dtype=float32), 'training/v_loss': Array(1557.6602, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.11755996, 0.14312524], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 8.97018 , 12.343234], dtype=float32), 'eval/episode_reward': Array([-10295.133,  11934.086], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.10570092, 0.1472884 ], dtype=float32), 'eval/avg_episode_length': Array([979.5078 , 113.25565], dtype=float32), 'eval/epoch_eval_time': 3.651398181915283, 'eval/sps': 35055.06483350978}
I0728 19:01:47.989708 139857045534528 train.py:379] starting iteration 4, 44564480 steps, 189.75851798057556
I0728 19:02:27.448551 139857045534528 train.py:394] {'eval/walltime': 33.46877670288086, 'training/sps': 311177.9351503085, 'training/walltime': 189.28252387046814, 'training/entropy_loss': Array(-0.00376003, dtype=float32), 'training/policy_loss': Array(-0.00121282, dtype=float32), 'training/total_loss': Array(6176.5605, dtype=float32), 'training/v_loss': Array(6176.565, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.08109406, 0.12022662], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 6.4067054, 10.078967 ], dtype=float32), 'eval/episode_reward': Array([-7799.1235, 10096.553 ], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.0743429 , 0.12057141], dtype=float32), 'eval/avg_episode_length': Array([701.9219 , 350.31372], dtype=float32), 'eval/epoch_eval_time': 3.6512632369995117, 'eval/sps': 35056.36041327609}
I0728 19:02:27.450186 139857045534528 train.py:379] starting iteration 5, 55705600 steps, 229.21899557113647
I0728 19:03:07.565318 139857045534528 train.py:394] {'eval/walltime': 37.20720934867859, 'training/sps': 306302.76929240493, 'training/walltime': 225.6554238796234, 'training/entropy_loss': Array(-0.00549978, dtype=float32), 'training/policy_loss': Array(-0.00140725, dtype=float32), 'training/total_loss': Array(14782.633, dtype=float32), 'training/v_loss': Array(14782.638, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.08028583, 0.11042683], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([6.5338216, 9.176949 ], dtype=float32), 'eval/episode_reward': Array([-7200.425,  9642.433], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.07512844, 0.10938279], dtype=float32), 'eval/avg_episode_length': Array([505.1172 , 406.99533], dtype=float32), 'eval/epoch_eval_time': 3.7384326457977295, 'eval/sps': 34238.94774294819}
I0728 19:03:07.566943 139857045534528 train.py:379] starting iteration 6, 66846720 steps, 269.3357529640198
I0728 19:03:47.919262 139857045534528 train.py:394] {'eval/walltime': 41.02009129524231, 'training/sps': 304940.6196387898, 'training/walltime': 262.1907992362976, 'training/entropy_loss': Array(-0.00643774, dtype=float32), 'training/policy_loss': Array(-9.41418e-06, dtype=float32), 'training/total_loss': Array(11619.569, dtype=float32), 'training/v_loss': Array(11619.576, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.07639208, 0.1205821 ], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 6.1961   , 10.0368595], dtype=float32), 'eval/episode_reward': Array([-7138.997, 10713.499], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.0713726 , 0.12004296], dtype=float32), 'eval/avg_episode_length': Array([439.95312, 403.5675 ], dtype=float32), 'eval/epoch_eval_time': 3.8128819465637207, 'eval/sps': 33570.407317582256}
I0728 19:03:47.920881 139857045534528 train.py:379] starting iteration 7, 77987840 steps, 309.6896917819977
I0728 19:04:28.275649 139857045534528 train.py:394] {'eval/walltime': 44.83976769447327, 'training/sps': 304974.23158061923, 'training/walltime': 298.72214794158936, 'training/entropy_loss': Array(-0.00765369, dtype=float32), 'training/policy_loss': Array(0.00015557, dtype=float32), 'training/total_loss': Array(10109.536, dtype=float32), 'training/v_loss': Array(10109.545, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.06658243, 0.09900859], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([5.37222 , 8.197365], dtype=float32), 'eval/episode_reward': Array([-6433.298,  9221.67 ], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.06069536, 0.09818952], dtype=float32), 'eval/avg_episode_length': Array([455.7422 , 421.53925], dtype=float32), 'eval/epoch_eval_time': 3.819676399230957, 'eval/sps': 33510.69216904635}
I0728 19:04:28.277250 139857045534528 train.py:379] starting iteration 8, 89128960 steps, 350.04606008529663
I0728 19:05:08.696765 139857045534528 train.py:394] {'eval/walltime': 48.683236837387085, 'training/sps': 304630.6324835277, 'training/walltime': 335.29470109939575, 'training/entropy_loss': Array(-0.00623379, dtype=float32), 'training/policy_loss': Array(0.00045844, dtype=float32), 'training/total_loss': Array(9344.389, dtype=float32), 'training/v_loss': Array(9344.395, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.07669188, 0.10937846], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([6.275901, 9.110869], dtype=float32), 'eval/episode_reward': Array([-7631.9863, 10873.703 ], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.07154141, 0.10873841], dtype=float32), 'eval/avg_episode_length': Array([447.5   , 423.1211], dtype=float32), 'eval/epoch_eval_time': 3.8434691429138184, 'eval/sps': 33303.24642673218}
I0728 19:05:09.055729 139857045534528 train.py:410] total steps: 100270080
