I0728 17:19:31.583101 139646343227200 low_level_env.py:188] Initialising environment...
I0728 17:19:31.883642 139646343227200 low_level_env.py:294] Environment initialised.
I0728 17:19:31.888775 139646343227200 train.py:118] JAX is running on GPU.
I0728 17:19:31.888833 139646343227200 train.py:121] Device count: 2, process count: 1 (id 0), local device count: 2, devices to be used count: 2
I0728 17:19:38.140577 139646343227200 train.py:367] Running initial eval
I0728 17:19:53.572456 139646343227200 train.py:373] {'eval/walltime': 15.298875570297241, 'eval/episode_goal_distance_relative_frame_normalised': Array([0.3099683 , 0.12746343], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([26.246725, 10.923604], dtype=float32), 'eval/episode_reward': Array([-21763.643,  12665.281], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.30594352, 0.12983955], dtype=float32), 'eval/avg_episode_length': Array([852.4219 , 353.47568], dtype=float32), 'eval/epoch_eval_time': 15.298875570297241, 'eval/sps': 8366.627953266836}
I0728 17:19:53.573775 139646343227200 train.py:379] starting iteration 0, 0 steps, 21.685012340545654
I0728 17:20:44.270842 139646343227200 train.py:394] {'eval/walltime': 18.910933017730713, 'training/sps': 236638.79174177925, 'training/walltime': 47.080700159072876, 'training/entropy_loss': Array(-0.03651667, dtype=float32), 'training/policy_loss': Array(-0.00444436, dtype=float32), 'training/total_loss': Array(28867.27, dtype=float32), 'training/v_loss': Array(28867.309, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.13352557, 0.10658738], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([11.046284,  9.098688], dtype=float32), 'eval/episode_reward': Array([-12916.472 ,   7742.5054], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.12101679, 0.11195032], dtype=float32), 'eval/avg_episode_length': Array([899.03906, 300.28323], dtype=float32), 'eval/epoch_eval_time': 3.6120574474334717, 'eval/sps': 35436.867176891035}
I0728 17:20:44.287270 139646343227200 train.py:379] starting iteration 1, 11141120 steps, 72.39850854873657
I0728 17:21:23.070003 139646343227200 train.py:394] {'eval/walltime': 22.542385816574097, 'training/sps': 316986.06121625565, 'training/walltime': 82.22773456573486, 'training/entropy_loss': Array(-0.01996023, dtype=float32), 'training/policy_loss': Array(-0.00167199, dtype=float32), 'training/total_loss': Array(4468.234, dtype=float32), 'training/v_loss': Array(4468.255, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.11993712, 0.1184907 ], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 9.705761, 10.170198], dtype=float32), 'eval/episode_reward': Array([-9995.057,  8261.938], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.10438293, 0.1253461 ], dtype=float32), 'eval/avg_episode_length': Array([899.0469 , 300.26035], dtype=float32), 'eval/epoch_eval_time': 3.631452798843384, 'eval/sps': 35247.60119166851}
I0728 17:21:23.072007 139646343227200 train.py:379] starting iteration 2, 22282240 steps, 111.18324708938599
I0728 17:22:01.865075 139646343227200 train.py:394] {'eval/walltime': 26.188722848892212, 'training/sps': 317021.3251508984, 'training/walltime': 117.37085938453674, 'training/entropy_loss': Array(-0.01122987, dtype=float32), 'training/policy_loss': Array(-0.00151753, dtype=float32), 'training/total_loss': Array(3973.712, dtype=float32), 'training/v_loss': Array(3973.725, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.1389223 , 0.13320924], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([11.332158, 11.397044], dtype=float32), 'eval/episode_reward': Array([-9959.608,  9695.723], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.12483937, 0.14028506], dtype=float32), 'eval/avg_episode_length': Array([875.59375, 329.14838], dtype=float32), 'eval/epoch_eval_time': 3.6463370323181152, 'eval/sps': 35103.72158840883}
I0728 17:22:01.866674 139646343227200 train.py:379] starting iteration 3, 33423360 steps, 149.9779133796692
I0728 17:22:40.712980 139646343227200 train.py:394] {'eval/walltime': 29.83256220817566, 'training/sps': 316525.6521772115, 'training/walltime': 152.5690176486969, 'training/entropy_loss': Array(-0.00599282, dtype=float32), 'training/policy_loss': Array(-0.00224251, dtype=float32), 'training/total_loss': Array(2521.7026, dtype=float32), 'training/v_loss': Array(2521.711, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.12222576, 0.13045453], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 9.692331, 11.373102], dtype=float32), 'eval/episode_reward': Array([-7249.9043,  8871.979 ], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.10928968, 0.13654134], dtype=float32), 'eval/avg_episode_length': Array([813.625  , 387.97113], dtype=float32), 'eval/epoch_eval_time': 3.6438393592834473, 'eval/sps': 35127.78346660455}
I0728 17:22:40.714500 139646343227200 train.py:379] starting iteration 4, 44564480 steps, 188.8257396221161
I0728 17:23:20.032506 139646343227200 train.py:394] {'eval/walltime': 33.503212451934814, 'training/sps': 312571.77372688404, 'training/walltime': 188.21241521835327, 'training/entropy_loss': Array(0.00038573, dtype=float32), 'training/policy_loss': Array(-0.00240593, dtype=float32), 'training/total_loss': Array(2363.23, dtype=float32), 'training/v_loss': Array(2363.232, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.12085833, 0.12355493], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 9.440831 , 10.7638235], dtype=float32), 'eval/episode_reward': Array([-8898.832,  9467.062], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.10903269, 0.1286993 ], dtype=float32), 'eval/avg_episode_length': Array([871.6875 , 330.43964], dtype=float32), 'eval/epoch_eval_time': 3.6706502437591553, 'eval/sps': 34871.20578094461}
I0728 17:23:20.034022 139646343227200 train.py:379] starting iteration 5, 55705600 steps, 228.1452615261078
I0728 17:23:59.718728 139646343227200 train.py:394] {'eval/walltime': 37.24882769584656, 'training/sps': 310033.52782195515, 'training/walltime': 224.14762544631958, 'training/entropy_loss': Array(0.00447095, dtype=float32), 'training/policy_loss': Array(-0.00242271, dtype=float32), 'training/total_loss': Array(1828.419, dtype=float32), 'training/v_loss': Array(1828.4167, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.1119132 , 0.11831217], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 8.691837, 10.426078], dtype=float32), 'eval/episode_reward': Array([-5427.0195,  7243.0205], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.10002524, 0.12334737], dtype=float32), 'eval/avg_episode_length': Array([782.33594, 411.34708], dtype=float32), 'eval/epoch_eval_time': 3.745615243911743, 'eval/sps': 34173.291078963804}
I0728 17:23:59.720228 139646343227200 train.py:379] starting iteration 6, 66846720 steps, 267.831467628479
I0728 17:24:39.609495 139646343227200 train.py:394] {'eval/walltime': 41.05926990509033, 'training/sps': 308832.90593670576, 'training/walltime': 260.2225377559662, 'training/entropy_loss': Array(0.00721985, dtype=float32), 'training/policy_loss': Array(-0.00214316, dtype=float32), 'training/total_loss': Array(1744.5535, dtype=float32), 'training/v_loss': Array(1744.5486, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.1230122 , 0.12717994], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 9.579155, 11.081355], dtype=float32), 'eval/episode_reward': Array([-6691.4404,  9582.602 ], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.11148999, 0.13230504], dtype=float32), 'eval/avg_episode_length': Array([771.66406, 415.4879 ], dtype=float32), 'eval/epoch_eval_time': 3.8104422092437744, 'eval/sps': 33591.90166681548}
I0728 17:24:39.611021 139646343227200 train.py:379] starting iteration 7, 77987840 steps, 307.72226095199585
I0728 17:25:19.418749 139646343227200 train.py:394] {'eval/walltime': 44.89214825630188, 'training/sps': 309720.501395561, 'training/walltime': 296.1940667629242, 'training/entropy_loss': Array(0.00786213, dtype=float32), 'training/policy_loss': Array(-0.00190818, dtype=float32), 'training/total_loss': Array(1604.747, dtype=float32), 'training/v_loss': Array(1604.741, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.10600254, 0.11989014], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([ 8.075364, 10.575187], dtype=float32), 'eval/episode_reward': Array([-5299.3574,  7323.043 ], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.09335409, 0.12518251], dtype=float32), 'eval/avg_episode_length': Array([784.03906, 405.39096], dtype=float32), 'eval/epoch_eval_time': 3.832878351211548, 'eval/sps': 33395.268065197015}
I0728 17:25:19.420175 139646343227200 train.py:379] starting iteration 8, 89128960 steps, 347.5314154624939
I0728 17:25:59.452652 139646343227200 train.py:394] {'eval/walltime': 48.784759521484375, 'training/sps': 308309.565284333, 'training/walltime': 332.33021450042725, 'training/entropy_loss': Array(0.00825029, dtype=float32), 'training/policy_loss': Array(-0.00175659, dtype=float32), 'training/total_loss': Array(1507.0385, dtype=float32), 'training/v_loss': Array(1507.032, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.08155996, 0.09863939], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([5.959079, 8.669291], dtype=float32), 'eval/episode_reward': Array([-5783.4233,  6189.073 ], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.06602379, 0.10328411], dtype=float32), 'eval/avg_episode_length': Array([841.9219 , 358.90543], dtype=float32), 'eval/epoch_eval_time': 3.892611265182495, 'eval/sps': 32882.81086398157}
I0728 17:25:59.799524 139646343227200 train.py:410] total steps: 100270080
