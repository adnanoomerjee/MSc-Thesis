I0728 16:01:43.570883 140511707764544 low_level_env.py:188] Initialising environment...
I0728 16:01:43.872358 140511707764544 low_level_env.py:294] Environment initialised.
I0728 16:01:43.881851 140511707764544 train.py:118] JAX is running on GPU.
I0728 16:01:43.881907 140511707764544 train.py:121] Device count: 2, process count: 1 (id 0), local device count: 2, devices to be used count: 2
I0728 16:01:50.043410 140511707764544 train.py:367] Running initial eval
I0728 16:02:05.418370 140511707764544 train.py:373] {'eval/walltime': 15.233306646347046, 'eval/episode_goal_distance_relative_frame_normalised': Array([0.2901414 , 0.11077533], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([24.539974,  9.462934], dtype=float32), 'eval/episode_reward': Array([-145.56119,  108.5937 ], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.28614676, 0.11262305], dtype=float32), 'eval/avg_episode_length': Array([671.625  , 466.14478], dtype=float32), 'eval/epoch_eval_time': 15.233306646347046, 'eval/sps': 8402.64054099472}
I0728 16:02:05.419574 140511707764544 train.py:379] starting iteration 0, 0 steps, 21.537736654281616
I0728 16:02:38.387594 140511707764544 train.py:394] {'eval/walltime': 18.86160945892334, 'training/sps': 189892.6260744681, 'training/walltime': 29.335314989089966, 'training/entropy_loss': Array(-0.03054323, dtype=float32), 'training/policy_loss': Array(-0.0109276, dtype=float32), 'training/total_loss': Array(85.74928, dtype=float32), 'training/v_loss': Array(85.79076, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([0.7007066 , 0.34018558], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([59.55841 , 28.916853], dtype=float32), 'eval/episode_reward': Array([713.7429 , 451.01672], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([0.6997045 , 0.34218913], dtype=float32), 'eval/avg_episode_length': Array([719.7656 , 447.98654], dtype=float32), 'eval/epoch_eval_time': 3.628302812576294, 'eval/sps': 35278.20212699198}
I0728 16:02:38.410417 140511707764544 train.py:379] starting iteration 1, 5570560 steps, 54.52856230735779
I0728 16:02:59.164677 140511707764544 train.py:394] {'eval/walltime': 22.49658703804016, 'training/sps': 325481.01467355946, 'training/walltime': 46.45016884803772, 'training/entropy_loss': Array(0.00648133, dtype=float32), 'training/policy_loss': Array(-0.01332834, dtype=float32), 'training/total_loss': Array(186.70213, dtype=float32), 'training/v_loss': Array(186.70898, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([2.7712421, 1.5633785], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([235.8722 , 133.09196], dtype=float32), 'eval/episode_reward': Array([1850.0576, 1094.9727], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([2.7738507, 1.5670359], dtype=float32), 'eval/avg_episode_length': Array([752.71094, 424.90112], dtype=float32), 'eval/epoch_eval_time': 3.6349775791168213, 'eval/sps': 35213.422150213024}
I0728 16:02:59.166286 140511707764544 train.py:379] starting iteration 2, 11141120 steps, 75.28444957733154
I0728 16:03:19.983193 140511707764544 train.py:394] {'eval/walltime': 26.13777232170105, 'training/sps': 324410.14111312677, 'training/walltime': 63.62151861190796, 'training/entropy_loss': Array(0.03010894, dtype=float32), 'training/policy_loss': Array(-0.00743114, dtype=float32), 'training/total_loss': Array(265.31287, dtype=float32), 'training/v_loss': Array(265.29016, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([4.557883 , 2.9304655], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([387.85968, 249.39378], dtype=float32), 'eval/episode_reward': Array([2751.1426, 1853.2539], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([4.5627866, 2.9361775], dtype=float32), 'eval/avg_episode_length': Array([685.3281 , 452.98947], dtype=float32), 'eval/epoch_eval_time': 3.6411852836608887, 'eval/sps': 35153.38825914054}
I0728 16:03:19.984760 140511707764544 train.py:379] starting iteration 3, 16711680 steps, 96.10292339324951
I0728 16:03:40.798012 140511707764544 train.py:394] {'eval/walltime': 29.778250455856323, 'training/sps': 324455.5465970832, 'training/walltime': 80.79046535491943, 'training/entropy_loss': Array(0.04643213, dtype=float32), 'training/policy_loss': Array(-0.00570912, dtype=float32), 'training/total_loss': Array(216.46646, dtype=float32), 'training/v_loss': Array(216.42572, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([6.5787063, 3.792108 ], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([559.8494 , 322.68842], dtype=float32), 'eval/episode_reward': Array([3827.549 , 2286.7415], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([6.5865602, 3.7989523], dtype=float32), 'eval/avg_episode_length': Array([743.27344, 435.30096], dtype=float32), 'eval/epoch_eval_time': 3.6404781341552734, 'eval/sps': 35160.21667568696}
I0728 16:03:40.799603 140511707764544 train.py:379] starting iteration 4, 22282240 steps, 116.91776704788208
I0728 16:04:01.696103 140511707764544 train.py:394] {'eval/walltime': 33.41964340209961, 'training/sps': 322905.48169756914, 'training/walltime': 98.04182934761047, 'training/entropy_loss': Array(0.06183229, dtype=float32), 'training/policy_loss': Array(-0.00357973, dtype=float32), 'training/total_loss': Array(154.31973, dtype=float32), 'training/v_loss': Array(154.26149, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([7.75213  , 3.9371524], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([659.7225 , 335.05566], dtype=float32), 'eval/episode_reward': Array([4506.8774, 2352.2268], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([7.761853 , 3.9439204], dtype=float32), 'eval/avg_episode_length': Array([798.1328, 399.8691], dtype=float32), 'eval/epoch_eval_time': 3.641392946243286, 'eval/sps': 35151.383519884526}
I0728 16:04:01.697667 140511707764544 train.py:379] starting iteration 5, 27852800 steps, 137.81583094596863
I0728 16:04:22.779953 140511707764544 train.py:394] {'eval/walltime': 37.06418204307556, 'training/sps': 319527.11478937085, 'training/walltime': 115.47559237480164, 'training/entropy_loss': Array(0.07553336, dtype=float32), 'training/policy_loss': Array(-0.0018982, dtype=float32), 'training/total_loss': Array(124.72287, dtype=float32), 'training/v_loss': Array(124.64924, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([7.5447936, 4.579466 ], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([642.05066, 389.74167], dtype=float32), 'eval/episode_reward': Array([4370.499 , 2718.7615], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([7.553704 , 4.5877604], dtype=float32), 'eval/avg_episode_length': Array([727.39844, 444.36127], dtype=float32), 'eval/epoch_eval_time': 3.644538640975952, 'eval/sps': 35121.04345962526}
I0728 16:04:22.781513 140511707764544 train.py:379] starting iteration 6, 33423360 steps, 158.8996765613556
I0728 16:04:44.024270 140511707764544 train.py:394] {'eval/walltime': 40.76490497589111, 'training/sps': 317620.6352300665, 'training/walltime': 133.01399946212769, 'training/entropy_loss': Array(0.0847438, dtype=float32), 'training/policy_loss': Array(-0.00085692, dtype=float32), 'training/total_loss': Array(113.97452, dtype=float32), 'training/v_loss': Array(113.890625, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([7.76303 , 4.778331], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([660.61005, 406.68134], dtype=float32), 'eval/episode_reward': Array([4494.9478, 2837.3335], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([7.772375 , 4.7866507], dtype=float32), 'eval/avg_episode_length': Array([727.53906, 444.1325 ], dtype=float32), 'eval/epoch_eval_time': 3.7007229328155518, 'eval/sps': 34587.83657241159}
I0728 16:04:44.025837 140511707764544 train.py:379] starting iteration 7, 38993920 steps, 180.14400053024292
I0728 16:05:05.388342 140511707764544 train.py:394] {'eval/walltime': 44.52710556983948, 'training/sps': 316569.77799529815, 'training/walltime': 150.6106255054474, 'training/entropy_loss': Array(0.09194437, dtype=float32), 'training/policy_loss': Array(-1.15564e-05, dtype=float32), 'training/total_loss': Array(109.16211, dtype=float32), 'training/v_loss': Array(109.070175, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([8.581946 , 4.6006827], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([730.3334, 391.5174], dtype=float32), 'eval/episode_reward': Array([4989.3687, 2716.0483], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([8.592849, 4.608232], dtype=float32), 'eval/avg_episode_length': Array([789.83594, 406.47955], dtype=float32), 'eval/epoch_eval_time': 3.7622005939483643, 'eval/sps': 34022.64095271598}
I0728 16:05:05.389908 140511707764544 train.py:379] starting iteration 8, 44564480 steps, 201.50807118415833
I0728 16:05:26.836704 140511707764544 train.py:394] {'eval/walltime': 48.32344198226929, 'training/sps': 315682.7894828277, 'training/walltime': 168.25669360160828, 'training/entropy_loss': Array(0.09606396, dtype=float32), 'training/policy_loss': Array(0.00087266, dtype=float32), 'training/total_loss': Array(119.85521, dtype=float32), 'training/v_loss': Array(119.75828, dtype=float32), 'eval/episode_goal_distance_relative_frame_normalised': Array([8.37389  , 4.8798556], dtype=float32), 'eval/episode_goal_distance_world_frame': Array([712.60614, 415.29657], dtype=float32), 'eval/episode_reward': Array([4870.5063, 2897.9817], dtype=float32), 'eval/episode_root_goal_distance_normalised': Array([8.384205, 4.888197], dtype=float32), 'eval/avg_episode_length': Array([751.0625 , 431.17426], dtype=float32), 'eval/epoch_eval_time': 3.7963364124298096, 'eval/sps': 33716.71688022896}
I0728 16:05:27.207824 140511707764544 train.py:410] total steps: 50135040
